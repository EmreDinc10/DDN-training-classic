{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Colab & GPU Verification\n",
        "\n",
        "Run this cell to verify:\n",
        "1. Connection to Google Colab\n",
        "2. GPU availability (A100, V100, T4, etc.)\n",
        "3. CUDA functionality\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verification Code - Copy and run this in Colab\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COLAB & GPU VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Verify Colab Connection\n",
        "print(\"\\n[1] COLAB CONNECTION CHECK\")\n",
        "print(\"-\" * 70)\n",
        "try:\n",
        "    import google.colab\n",
        "    print(\"✓ Running in Google Colab\")\n",
        "    print(f\"✓ Colab module imported successfully\")\n",
        "    colab_connected = True\n",
        "except ImportError:\n",
        "    print(\"✗ NOT running in Google Colab\")\n",
        "    colab_connected = False\n",
        "\n",
        "print(f\"\\nCurrent directory: {os.getcwd()}\")\n",
        "if \"/content\" in os.getcwd():\n",
        "    print(\"✓ In Colab filesystem (/content)\")\n",
        "\n",
        "# 2. Verify GPU/CUDA\n",
        "print(\"\\n[2] GPU/CUDA CHECK\")\n",
        "print(\"-\" * 70)\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    \n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    print(f\"CUDA available: {cuda_available}\")\n",
        "    \n",
        "    if cuda_available:\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"Number of GPUs: {gpu_count}\")\n",
        "        \n",
        "        for i in range(gpu_count):\n",
        "            gpu_name = torch.cuda.get_device_name(i)\n",
        "            gpu_props = torch.cuda.get_device_properties(i)\n",
        "            gpu_memory_gb = gpu_props.total_memory / 1e9\n",
        "            \n",
        "            print(f\"\\n  GPU {i}:\")\n",
        "            print(f\"    Name: {gpu_name}\")\n",
        "            print(f\"    Memory: {gpu_memory_gb:.2f} GB\")\n",
        "            print(f\"    Compute Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
        "            \n",
        "            if \"A100\" in gpu_name:\n",
        "                print(f\"    ✓ A100 GPU detected! (Best for training!)\")\n",
        "            elif \"V100\" in gpu_name:\n",
        "                print(f\"    ✓ V100 GPU detected (Good)\")\n",
        "            elif \"T4\" in gpu_name:\n",
        "                print(f\"    ✓ T4 GPU detected (Minimum)\")\n",
        "        \n",
        "        # Test CUDA operation\n",
        "        test_tensor = torch.randn(10, 10).cuda()\n",
        "        print(f\"\\n✓ CUDA operations working (test tensor created on GPU)\")\n",
        "        del test_tensor\n",
        "        torch.cuda.empty_cache()\n",
        "    else:\n",
        "        print(\"\\n✗ NO GPU DETECTED!\")\n",
        "        print(\"\\n  To enable GPU:\")\n",
        "        print(\"  1. Runtime → Change runtime type\")\n",
        "        print(\"  2. Set Hardware accelerator: GPU\")\n",
        "        print(\"  3. Save and restart runtime\")\n",
        "        \n",
        "except ImportError:\n",
        "    print(\"✗ PyTorch not installed\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Error: {e}\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_name = torch.cuda.get_device_name(0)\n",
        "        print(f\"✓ Colab: Connected\")\n",
        "        print(f\"✓ GPU: {gpu_name}\")\n",
        "        if \"A100\" in gpu_name:\n",
        "            print(\"✅ READY! A100 GPU detected - Best for training!\")\n",
        "        else:\n",
        "            print(\"✅ READY! GPU available for training\")\n",
        "    else:\n",
        "        print(\"✓ Colab: Connected\")\n",
        "        print(\"✗ GPU: Not available - Enable GPU first!\")\n",
        "except:\n",
        "    pass\n",
        "print(\"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
